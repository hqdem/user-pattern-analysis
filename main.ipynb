{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Сбор и предварительная обработка датасета",
   "id": "dadd519da87485dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T13:54:03.049143Z",
     "start_time": "2025-04-06T13:54:03.047039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "5c531d6c34cf04d0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dailydialog",
   "id": "6e04d5fc6f88806c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Собираем датасет из сырых данных",
   "id": "6bd5d605e3917188"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T13:54:05.252964Z",
     "start_time": "2025-04-06T13:54:04.939865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('data/dailydialog/dialogues_text.txt', 'r', encoding='utf-8') as f:\n",
    "    dialogues = [line.strip().split('__eou__')[:-1] for line in f.readlines()]  # remove last empty after __eou__\n",
    "\n",
    "with open('data/dailydialog/dialogues_topic.txt', 'r', encoding='utf-8') as f:\n",
    "    topics = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "with open('data/dailydialog/dialogues_act.txt', 'r', encoding='utf-8') as f:\n",
    "    acts = [list(map(int, line.strip().split())) for line in f.readlines()]\n",
    "\n",
    "with open('data/dailydialog/dialogues_emotion.txt', 'r', encoding='utf-8') as f:\n",
    "    emotions = [list(map(int, line.strip().split())) for line in f.readlines()]\n",
    "\n",
    "# Prepare dataframe\n",
    "data = []\n",
    "\n",
    "for dialog_id, (utterances, topic, act_list, emotion_list) in enumerate(zip(dialogues, topics, acts, emotions)):\n",
    "    previous_person_message = None\n",
    "    for i, (message, act, emotion) in enumerate(zip(utterances, act_list, emotion_list)):\n",
    "        entry = {\n",
    "            \"dialog_id\": dialog_id,\n",
    "            \"person_message\": message.strip(),\n",
    "            \"previous_person_message\": previous_person_message,\n",
    "            \"topic\": topic,    # {1: Ordinary Life, 2: School Life, 3: Culture & Education, 4: Attitude & Emotion, 5: Relationship, 6: Tourism , 7: Health, 8: Work, 9: Politics, 10: Finance}\n",
    "            \"act\": act,        # { 1: inform，2: question, 3: directive, 4: commissive }\n",
    "            \"emotion\": emotion # { 0: no emotion, 1: anger, 2: disgust, 3: fear, 4: happiness, 5: sadness, 6: surprise}\n",
    "        }\n",
    "        previous_person_message = message.strip()\n",
    "        data.append(entry)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('data/dailydialog/processed/dialogues_topic.csv', index=False)\n",
    "df.head(10)"
   ],
   "id": "a212b055abfd16ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   dialog_id                                     person_message  \\\n",
       "0          0                               The kitchen stinks .   \n",
       "1          0                       I'll throw out the garbage .   \n",
       "2          1  So Dick , how about getting some coffee for to...   \n",
       "3          1  Coffee ? I don ’ t honestly like that kind of ...   \n",
       "4          1  Come on , you can at least try a little , besi...   \n",
       "5          1  What ’ s wrong with that ? Cigarette is the th...   \n",
       "6          1                                Not for me , Dick .   \n",
       "7          2  Are things still going badly with your housegu...   \n",
       "8          2  Getting worse . Now he ’ s eating me out of ho...   \n",
       "9          2  Leo , I really think you ’ re beating around t...   \n",
       "\n",
       "                             previous_person_message  topic  act  emotion  \n",
       "0                                               None      1    3        2  \n",
       "1                               The kitchen stinks .      1    4        0  \n",
       "2                                               None      1    3        4  \n",
       "3  So Dick , how about getting some coffee for to...      1    4        2  \n",
       "4  Coffee ? I don ’ t honestly like that kind of ...      1    3        0  \n",
       "5  Come on , you can at least try a little , besi...      1    1        1  \n",
       "6  What ’ s wrong with that ? Cigarette is the th...      1    1        0  \n",
       "7                                               None      1    2        0  \n",
       "8  Are things still going badly with your housegu...      1    1        1  \n",
       "9  Getting worse . Now he ’ s eating me out of ho...      1    3        0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>person_message</th>\n",
       "      <th>previous_person_message</th>\n",
       "      <th>topic</th>\n",
       "      <th>act</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The kitchen stinks .</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I'll throw out the garbage .</td>\n",
       "      <td>The kitchen stinks .</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>So Dick , how about getting some coffee for to...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee ? I don ’ t honestly like that kind of ...</td>\n",
       "      <td>So Dick , how about getting some coffee for to...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Come on , you can at least try a little , besi...</td>\n",
       "      <td>Coffee ? I don ’ t honestly like that kind of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>What ’ s wrong with that ? Cigarette is the th...</td>\n",
       "      <td>Come on , you can at least try a little , besi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Not for me , Dick .</td>\n",
       "      <td>What ’ s wrong with that ? Cigarette is the th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Are things still going badly with your housegu...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Getting worse . Now he ’ s eating me out of ho...</td>\n",
       "      <td>Are things still going badly with your housegu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Leo , I really think you ’ re beating around t...</td>\n",
       "      <td>Getting worse . Now he ’ s eating me out of ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Преобразование текста в числовой формат (word2vec, bert)",
   "id": "d38b21ccd724d25d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### word2vec",
   "id": "f0132f8cc0c2dde5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:12:13.645672Z",
     "start_time": "2025-04-06T17:12:10.199679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_csv(\"data/dailydialog/processed/dialogues_topic.csv\")\n",
    "\n",
    "# Объединяем person_message и previous_person_message\n",
    "# df['text_combined'] = df['previous_person_message'].fillna('') + ' ' + df['person_message'] TODO: check\n",
    "df['text_combined'] = df['person_message']\n",
    "\n",
    "# Токенизация\n",
    "sentences = df['text_combined'].apply(lambda x: x.lower().split()).tolist()\n",
    "\n",
    "# Обучаем модель Word2Vec\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Функция усреднения эмбеддингов\n",
    "def get_avg_w2v(sentence, model):\n",
    "    words = sentence.lower().split()\n",
    "    valid_words = [w for w in words if w in model.wv]\n",
    "    if not valid_words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[valid_words], axis=0)\n",
    "\n",
    "# Применим к каждому тексту\n",
    "text_vectors = np.array([get_avg_w2v(t, w2v_model) for t in df['text_combined']])\n",
    "\n",
    "# Кодируем topic и act\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "cat_features_w2v = encoder.fit_transform(df[['topic', 'act']])\n",
    "\n",
    "# Объединяем признаки\n",
    "# X_w2v = np.hstack([text_vectors, cat_features_w2v]) // TODO: check\n",
    "X_w2v = text_vectors\n",
    "y_w2v = df['emotion'].values\n",
    "\n",
    "# Разделим на 80% train и 20% test\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(\n",
    "    X_w2v,\n",
    "    y_w2v,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_w2v\n",
    ")\n"
   ],
   "id": "4a13be5f3f7a51aa",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### bert",
   "id": "c760956791795399"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:16:02.405630Z",
     "start_time": "2025-04-06T17:15:51.602610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_csv(\"data/dailydialog/processed/dialogues_topic.csv\")\n",
    "# df['text_combined'] = df['previous_person_message'].fillna('') + ' ' + df['person_message'] // TODO: check\n",
    "df['text_combined'] = df['person_message']\n",
    "\n",
    "# Подключаем BERT\n",
    "model_name = \"Kostya165/rubert_emotion_slicer\" # or bert-base-uncased\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "bert_model.to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs.to(device))  # только модель на MPS\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()  # возвращаем на CPU\n",
    "    return cls_embedding\n",
    "\n",
    "bert_vectors = []\n",
    "for t in tqdm(df['text_combined'].tolist(), desc=\"Embedding BERT\"):\n",
    "    bert_vectors.append(get_bert_embedding(t))\n",
    "\n",
    "bert_vectors = np.array(bert_vectors)"
   ],
   "id": "c6c206d0a60b5f3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding BERT:   0%|          | 430/102979 [00:08<32:02, 53.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 34\u001B[39m\n\u001B[32m     32\u001B[39m bert_vectors = []\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tqdm(df[\u001B[33m'\u001B[39m\u001B[33mtext_combined\u001B[39m\u001B[33m'\u001B[39m].tolist(), desc=\u001B[33m\"\u001B[39m\u001B[33mEmbedding BERT\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     bert_vectors.append(\u001B[43mget_bert_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     36\u001B[39m bert_vectors = np.array(bert_vectors)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 29\u001B[39m, in \u001B[36mget_bert_embedding\u001B[39m\u001B[34m(text)\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m     28\u001B[39m     outputs = bert_model(**inputs.to(device))  \u001B[38;5;66;03m# только модель на MPS\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m cls_embedding = \u001B[43moutputs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlast_hidden_state\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m.numpy()  \u001B[38;5;66;03m# возвращаем на CPU\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cls_embedding\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T16:58:11.619778Z",
     "start_time": "2025-04-06T16:58:11.150668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bert_vectors1 = np.squeeze(bert_vectors, axis=1)  # убираем лишнюю размерность\n",
    "\n",
    "# Кодируем topic и act\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "cat_features_bert = encoder.fit_transform(df[['topic', 'act']])\n",
    "\n",
    "# Объединяем признаки\n",
    "# X_bert = np.hstack([bert_vectors1, cat_features_bert]) TODO: check\n",
    "X_bert = bert_vectors1\n",
    "y_bert = df['emotion'].values\n",
    "\n",
    "# Разделим на 80% train и 20% test\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(\n",
    "    X_bert,\n",
    "    y_bert,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_bert\n",
    ")\n"
   ],
   "id": "f1a9e11023104971",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Обучаем и сравниваем классификаторы",
   "id": "c9a5e297a6d183ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### word2vec",
   "id": "c4a6ed2c4bb4b93d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:14:13.244567Z",
     "start_time": "2025-04-06T17:12:49.672604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score\n",
    "\n",
    "\n",
    "def fit_predict_with_progress(model, X_train, y_train, X_test, desc):\n",
    "    tqdm.write(f\"Обучение: {desc}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    tqdm.write(f\"Предсказание: {desc}\")\n",
    "    return model.predict(X_test)\n",
    "\n",
    "logreg_w2v = LogisticRegression(max_iter=1000)\n",
    "y_pred_logreg_w2v = fit_predict_with_progress(logreg_w2v, X_train_w2v, y_train_w2v, X_test_w2v, \"Word2Vec + LogisticRegression\")\n",
    "\n",
    "rf_w2v = RandomForestClassifier()\n",
    "y_pred_rf_w2v = fit_predict_with_progress(rf_w2v, X_train_w2v, y_train_w2v, X_test_w2v, \"Word2Vec + RandomForest\")\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "y_pred_dummy_w2v = fit_predict_with_progress(dummy, X_train_w2v, y_train_w2v, X_test_w2v, \"Word2Vec + DummyClassifier\")\n",
    "\n",
    "print(\"Word2Vec - Logistic Regression Accuracy:\", accuracy_score(y_test_w2v, y_pred_logreg_w2v))\n",
    "print(\"Word2Vec - Random Forest Accuracy:\", accuracy_score(y_test_w2v, y_pred_rf_w2v))\n",
    "print(\"Word2Vec - Dummy Accuracy:\", accuracy_score(y_test_w2v, y_pred_dummy_w2v))\n",
    "\n",
    "print(\"Word2Vec - Logistic Regression f1:\", f1_score(y_test_w2v, y_pred_logreg_w2v, average='macro'))\n",
    "print(\"Word2Vec - Random Forest f1:\", f1_score(y_test_w2v, y_pred_rf_w2v, average='macro'))\n",
    "print(\"Word2Vec - Dummy f1:\", f1_score(y_test_w2v, y_pred_dummy_w2v, average='macro'))\n",
    "\n",
    "print(\"Word2Vec - Logistic Regression recall:\", recall_score(y_test_w2v, y_pred_logreg_w2v, average='macro'))\n",
    "print(\"Word2Vec - Random Forest recall:\", recall_score(y_test_w2v, y_pred_rf_w2v, average='macro'))\n",
    "print(\"Word2Vec - Dummy recall:\", recall_score(y_test_w2v, y_pred_dummy_w2v, average='macro'))\n",
    "\n",
    "print(\"\\n=== Classification Report: Word2Vec + Logistic Regression ===\")\n",
    "print(classification_report(y_test_w2v, y_pred_logreg_w2v))\n",
    "\n",
    "print(\"\\n=== Classification Report: Word2Vec + Random Forest ===\")\n",
    "print(classification_report(y_test_w2v, y_pred_rf_w2v))\n",
    "\n",
    "print(\"\\n=== Classification Report: Word2Vec + Dummy ===\")\n",
    "print(classification_report(y_test_w2v, y_pred_dummy_w2v))\n"
   ],
   "id": "1920e25e21c2b144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение: Word2Vec + LogisticRegression\n",
      "Предсказание: Word2Vec + LogisticRegression\n",
      "Обучение: Word2Vec + RandomForest\n",
      "Предсказание: Word2Vec + RandomForest\n",
      "Обучение: Word2Vec + DummyClassifier\n",
      "Предсказание: Word2Vec + DummyClassifier\n",
      "Word2Vec - Logistic Regression Accuracy: 0.8434647504369781\n",
      "Word2Vec - Random Forest Accuracy: 0.8499223150126238\n",
      "Word2Vec - Dummy Accuracy: 0.8309380462225675\n",
      "Word2Vec - Logistic Regression f1: 0.20843588266673657\n",
      "Word2Vec - Random Forest f1: 0.3503168813619682\n",
      "Word2Vec - Dummy f1: 0.12966624995264614\n",
      "Word2Vec - Logistic Regression recall: 0.1897338541777263\n",
      "Word2Vec - Random Forest recall: 0.2895348736348187\n",
      "Word2Vec - Dummy recall: 0.14285714285714285\n",
      "\n",
      "=== Classification Report: Word2Vec + Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91     17114\n",
      "           1       0.13      0.01      0.02       204\n",
      "           2       0.00      0.00      0.00        71\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.63      0.23      0.33      2577\n",
      "           5       0.27      0.03      0.05       230\n",
      "           6       0.47      0.09      0.15       365\n",
      "\n",
      "    accuracy                           0.84     20596\n",
      "   macro avg       0.34      0.19      0.21     20596\n",
      "weighted avg       0.80      0.84      0.80     20596\n",
      "\n",
      "\n",
      "=== Classification Report: Word2Vec + Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     17114\n",
      "           1       0.48      0.15      0.23       204\n",
      "           2       0.38      0.11      0.17        71\n",
      "           3       0.40      0.17      0.24        35\n",
      "           4       0.63      0.31      0.41      2577\n",
      "           5       0.37      0.10      0.16       230\n",
      "           6       0.62      0.21      0.31       365\n",
      "\n",
      "    accuracy                           0.85     20596\n",
      "   macro avg       0.54      0.29      0.35     20596\n",
      "weighted avg       0.82      0.85      0.82     20596\n",
      "\n",
      "\n",
      "=== Classification Report: Word2Vec + Dummy ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     17114\n",
      "           1       0.00      0.00      0.00       204\n",
      "           2       0.00      0.00      0.00        71\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.00      0.00      0.00      2577\n",
      "           5       0.00      0.00      0.00       230\n",
      "           6       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.83     20596\n",
      "   macro avg       0.12      0.14      0.13     20596\n",
      "weighted avg       0.69      0.83      0.75     20596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### bert",
   "id": "e6ae6ed1607dfd6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:05:55.113702Z",
     "start_time": "2025-04-06T16:58:22.148819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Обёртка для отслеживания этапов\n",
    "def fit_predict_with_progress(model, X_train, y_train, X_test, desc):\n",
    "    tqdm.write(f\"Обучение: {desc}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    tqdm.write(f\"Предсказание: {desc}\")\n",
    "    return model.predict(X_test)\n",
    "\n",
    "logreg_bert = LogisticRegression(max_iter=10000)\n",
    "y_pred_logreg_bert = fit_predict_with_progress(logreg_bert, X_train_bert, y_train_bert, X_test_bert, \"BERT + LogisticRegression\")\n",
    "\n",
    "rf_bert = RandomForestClassifier()\n",
    "y_pred_rf_bert = fit_predict_with_progress(rf_bert, X_train_bert, y_train_bert, X_test_bert, \"BERT + RandomForest\")\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "y_pred_dummy_bert = fit_predict_with_progress(dummy, X_train_bert, y_train_bert, X_test_bert, \"BERT + DummyClassifier\")\n",
    "\n",
    "print(\"BERT - Logistic Regression Accuracy:\", accuracy_score(y_test_bert, y_pred_logreg_bert))\n",
    "print(\"BERT - Random Forest Accuracy:\", accuracy_score(y_test_bert, y_pred_rf_bert))\n",
    "print(\"BERT - Dummy Accuracy:\", accuracy_score(y_test_bert, y_pred_dummy_bert))\n",
    "\n",
    "print(\"BERT - Logistic Regression f1:\", f1_score(y_test_bert, y_pred_logreg_bert, average='macro'))\n",
    "print(\"BERT - Random Forest f1:\", f1_score(y_test_bert, y_pred_rf_bert, average='macro'))\n",
    "print(\"BERT - Dummy f1:\", f1_score(y_test_bert, y_pred_dummy_bert, average='macro'))\n",
    "\n",
    "print(\"BERT - Logistic Regression recall:\", recall_score(y_test_bert, y_pred_logreg_bert, average='macro'))\n",
    "print(\"BERT - Random Forest recall:\", recall_score(y_test_bert, y_pred_rf_bert, average='macro'))\n",
    "print(\"BERT - Dummy recall:\", recall_score(y_test_bert, y_pred_dummy_bert, average='macro'))\n",
    "\n",
    "print(\"\\n=== Classification Report: BERT + Logistic Regression ===\")\n",
    "print(classification_report(y_test_bert, y_pred_logreg_bert))\n",
    "\n",
    "print(\"\\n=== Classification Report: BERT + Random Forest ===\")\n",
    "print(classification_report(y_test_bert, y_pred_rf_bert))\n",
    "\n",
    "print(\"\\n=== Classification Report: BERT + Dummy ===\")\n",
    "print(classification_report(y_test_bert, y_pred_dummy_bert))\n"
   ],
   "id": "2d1467485e0749d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение: BERT + LogisticRegression\n",
      "Предсказание: BERT + LogisticRegression\n",
      "Обучение: BERT + RandomForest\n",
      "Предсказание: BERT + RandomForest\n",
      "Обучение: BERT + DummyClassifier\n",
      "Предсказание: BERT + DummyClassifier\n",
      "BERT - Logistic Regression Accuracy: 0.8347737424742668\n",
      "BERT - Random Forest Accuracy: 0.8402602447077102\n",
      "BERT - Dummy Accuracy: 0.8309380462225675\n",
      "BERT - Logistic Regression f1: 0.1544869409978658\n",
      "BERT - Random Forest f1: 0.2723920908598581\n",
      "BERT - Dummy f1: 0.12966624995264614\n",
      "BERT - Logistic Regression recall: 0.15585365814630284\n",
      "BERT - Random Forest recall: 0.2248226889825826\n",
      "BERT - Dummy recall: 0.14285714285714285\n",
      "\n",
      "=== Classification Report: BERT + Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91     17114\n",
      "           1       0.00      0.00      0.00       204\n",
      "           2       0.00      0.00      0.00        71\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.56      0.10      0.17      2577\n",
      "           5       0.00      0.00      0.00       230\n",
      "           6       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.83     20596\n",
      "   macro avg       0.20      0.16      0.15     20596\n",
      "weighted avg       0.77      0.83      0.78     20596\n",
      "\n",
      "\n",
      "=== Classification Report: BERT + Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91     17114\n",
      "           1       0.79      0.13      0.22       204\n",
      "           2       0.44      0.06      0.10        71\n",
      "           3       0.43      0.09      0.14        35\n",
      "           4       0.59      0.17      0.27      2577\n",
      "           5       0.53      0.08      0.14       230\n",
      "           6       0.59      0.07      0.13       365\n",
      "\n",
      "    accuracy                           0.84     20596\n",
      "   macro avg       0.60      0.22      0.27     20596\n",
      "weighted avg       0.81      0.84      0.80     20596\n",
      "\n",
      "\n",
      "=== Classification Report: BERT + Dummy ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     17114\n",
      "           1       0.00      0.00      0.00       204\n",
      "           2       0.00      0.00      0.00        71\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.00      0.00      0.00      2577\n",
      "           5       0.00      0.00      0.00       230\n",
      "           6       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.83     20596\n",
      "   macro avg       0.12      0.14      0.13     20596\n",
      "weighted avg       0.69      0.83      0.75     20596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lerbuk/PycharmProjects/user-pattern-analysis/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
